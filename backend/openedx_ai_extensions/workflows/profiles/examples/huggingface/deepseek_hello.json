/*
Test experience. Use a hugging face hosted version of DeepSeek to say which llm model is answering
*/
{
  "orchestrator_class": "DirectLLMResponse",
  "processor_config": {
    "OpenEdXProcessor": {
    },
    "LLMProcessor": {
      "function": "greet_from_llm",
      "config": "deepseek"
    }
  },
  "actuator_config": {
    "UIComponents": {
      "request": {
        "component": "AIRequestComponent",
        "config": {
          "buttonText": "Hello AI",
          "customMessage": "DeepSeek will say hello"
        }
      },
      "response": {
        "component": "AIResponseComponent",
        "config": {
          "customMessage": "DeepSeek Response"
        }
      }
    }
  },
  "schema_version": "1.0",
}
