/*
Test experience. Use a self-hosted Ollama server with a Qwen model for the summary experience

For a tutor plugin for self-hosting a cpu only ollama.
See: https://gist.github.com/felipemontoya/509495d3fbaa696fa2b684880a8388da
*/
{
  "orchestrator_class": "DirectLLMResponse",
  "processor_config": {
    "OpenEdXProcessor": {
      "function": "get_location_content"
    },
    "LLMProcessor": {
      "function": "summarize_content",
      "provider": "qwen25"
    }
  },
  "actuator_config": {
    "UIComponents": {
      "request": {
        "component": "AIRequestComponent",
        "config": {
          "buttonText": "Summarize with Qwen",
          "customMessage": "Qwen will summarize the content"
        }
      },
      "response": {
        "component": "AIResponseComponent",
        "config": {
          "customMessage": "Summary by Qwen"
        }
      }
    }
  },
  "schema_version": "1.0",
}
